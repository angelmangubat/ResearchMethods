{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/LA+Gwccrh1mqvnF+qhSj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Pedestrian Detection Using SVM method**"],"metadata":{"id":"bqOBX6YlYydz"}},{"cell_type":"code","source":["#Map google drive and the input and output files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","Input_Path = \"/content/drive/My Drive/App/ResearchMethods/input/\"\n","TestPath = \"/content/drive/My Drive/App/ResearchMethods/input/Test/JPEGImages/\"\n","ValPath = \"/content/drive/My Drive/App/ResearchMethods/input/Val/JPEGImages/\"\n","TrainPath = \"/content/drive/My Drive/App/ResearchMethods/input/Train/JPEGImages/\"\n","Output_Path = \"/content/drive/My Drive/App/ResearchMethods/output/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDtl5-BBgS8o","executionInfo":{"status":"ok","timestamp":1702946770208,"user_tz":0,"elapsed":1620,"user":{"displayName":"Angelique Mangubat","userId":"07721384887300363972"}},"outputId":"73167be2-5701-4449-c70e-fa87be41196e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9zeM_rxUdyK"},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import cv2\n","\n","# List all files under the input directory\n","import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","for dirname, _, filenames in os.walk(TrainPath):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"]},{"cell_type":"markdown","source":["Import the Input images using a loop function that catches all images in JPG format."],"metadata":{"id":"XkoMEb8yZzwE"}},{"cell_type":"code","source":["#Import the Images\n","#files = os.listdir(\"/kaggle/input/pedestrian\")\n","files = os.listdir(TrainPath)\n","print(files)\n","img_path_list = []\n","for f in files:\n","    if f.endswith(\".jpg\"):\n","        img_path_list.append(f)\n","print(img_path_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_NFsnZQYyC-","executionInfo":{"status":"ok","timestamp":1702946958414,"user_tz":0,"elapsed":314,"user":{"displayName":"Angelique Mangubat","userId":"07721384887300363972"}},"outputId":"7e5b9e09-9604-41a6-e5ff-cc3c6571fd7f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['image (128).jpg', 'image (129).jpg', 'image (127).jpg', 'image (123).jpg', 'image (13).jpg', 'image (126).jpg', 'image (125).jpg', 'image (122).jpg', 'image (120).jpg', 'image (119).jpg', 'image (124).jpg', 'image (12).jpg', 'image (121).jpg', 'image (117).jpg', 'image (115).jpg', 'image (116).jpg', 'image (118).jpg', 'image (108).jpg', 'image (110).jpg', 'image (111).jpg', 'image (114).jpg', 'image (11).jpg', 'image (109).jpg', 'image (106).jpg', 'image (113).jpg', 'image (112).jpg', 'image (107).jpg', 'image (103).jpg', 'image (102).jpg', 'image (101).jpg', 'image (10).jpg', 'image (100).jpg', 'image (105).jpg', 'image (104).jpg', 'image (1).jpg', 'image (145).jpg', 'image (140).jpg', 'image (144).jpg', 'image (14).jpg', 'image (133).jpg', 'image (141).jpg', 'image (131).jpg', 'image (138).jpg', 'image (142).jpg', 'image (134).jpg', 'image (137).jpg', 'image (139).jpg', 'image (136).jpg', 'image (146).jpg', 'image (147).jpg', 'image (130).jpg', 'image (132).jpg', 'image (135).jpg', 'image (143).jpg', 'image (561).jpg', 'image (737).jpg', 'image (796).jpg', 'image (830).jpg', 'image (854).jpg', 'image (847).jpg', 'image (880).jpg', 'image (897).jpg', 'image (909).jpg', 'image (910).jpg', 'image (167).jpg', 'image (168).jpg', 'image (16).jpg', 'image (166).jpg', 'image (158).jpg', 'image (159).jpg', 'image (153).jpg', 'image (152).jpg', 'image (149).jpg', 'image (15).jpg', 'image (151).jpg', 'image (157).jpg', 'image (155).jpg', 'image (150).jpg', 'image (156).jpg', 'image (154).jpg', 'image (148).jpg']\n","['image (128).jpg', 'image (129).jpg', 'image (127).jpg', 'image (123).jpg', 'image (13).jpg', 'image (126).jpg', 'image (125).jpg', 'image (122).jpg', 'image (120).jpg', 'image (119).jpg', 'image (124).jpg', 'image (12).jpg', 'image (121).jpg', 'image (117).jpg', 'image (115).jpg', 'image (116).jpg', 'image (118).jpg', 'image (108).jpg', 'image (110).jpg', 'image (111).jpg', 'image (114).jpg', 'image (11).jpg', 'image (109).jpg', 'image (106).jpg', 'image (113).jpg', 'image (112).jpg', 'image (107).jpg', 'image (103).jpg', 'image (102).jpg', 'image (101).jpg', 'image (10).jpg', 'image (100).jpg', 'image (105).jpg', 'image (104).jpg', 'image (1).jpg', 'image (145).jpg', 'image (140).jpg', 'image (144).jpg', 'image (14).jpg', 'image (133).jpg', 'image (141).jpg', 'image (131).jpg', 'image (138).jpg', 'image (142).jpg', 'image (134).jpg', 'image (137).jpg', 'image (139).jpg', 'image (136).jpg', 'image (146).jpg', 'image (147).jpg', 'image (130).jpg', 'image (132).jpg', 'image (135).jpg', 'image (143).jpg', 'image (561).jpg', 'image (737).jpg', 'image (796).jpg', 'image (830).jpg', 'image (854).jpg', 'image (847).jpg', 'image (880).jpg', 'image (897).jpg', 'image (909).jpg', 'image (910).jpg', 'image (167).jpg', 'image (168).jpg', 'image (16).jpg', 'image (166).jpg', 'image (158).jpg', 'image (159).jpg', 'image (153).jpg', 'image (152).jpg', 'image (149).jpg', 'image (15).jpg', 'image (151).jpg', 'image (157).jpg', 'image (155).jpg', 'image (150).jpg', 'image (156).jpg', 'image (154).jpg', 'image (148).jpg']\n"]}]},{"cell_type":"markdown","source":["Use SVM classifier"],"metadata":{"id":"JeprQnCYaO5c"}},{"cell_type":"code","source":["#Use of HOG Identifier\n","hog = cv2.HOGDescriptor()\n","#Add SVM descriptor\n","hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"],"metadata":{"id":"G-rP3Iz3ZVWM","executionInfo":{"status":"ok","timestamp":1702946963575,"user_tz":0,"elapsed":219,"user":{"displayName":"Angelique Mangubat","userId":"07721384887300363972"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Steps:\n","1.   Import images using imread function.\n","2.   Detect pedestrians with HOG descriptor. Also, used scalefactor and minNeighbors parameters for fine tuning. The (8,8) padding ensures that the size of the image does not change by adding 0s to the edges of the image.\n","3.   Draw a rectangle on the pedestrians found and display them on the screen."],"metadata":{"id":"DVIav5ylaSfi"}},{"cell_type":"code","source":["#a=\"/kaggle/input/pedestrian/\"\n","a=TestPath\n","for imagePath in img_path_list:\n","    print(imagePath)\n","\n","    image = cv2.imread(a+imagePath)\n","    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    (rects, weights) = hog.detectMultiScale(image, padding = (8,8), scale = 1.01)\n","\n","    for (i,(x,y,w,h)) in enumerate(rects):\n","        cv2.rectangle(image, (x,y),(x+w,y+h),(0,0,255),2)\n","        cv2.putText(image, \"Pedestrian {}\".format(i+1), (x,y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0,255,255),2)\n","    plt.figure(),plt.imshow(image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18A-ANBoHn-FHprePTROLe5rP2L4b0Ivo"},"id":"S62LolrtZtPh","executionInfo":{"status":"error","timestamp":1702947022086,"user_tz":0,"elapsed":24694,"user":{"displayName":"Angelique Mangubat","userId":"07721384887300363972"}},"outputId":"4d311337-b84a-4283-a97f-1961d4650204"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Algorithm Reference: https://www.kaggle.com/code/cengizalbayrak/yaya-tespiti-pedestrian-detection\n","\n","Dataset Reference: https://www.kaggle.com/datasets/karthika95/pedestrian-detection/data"],"metadata":{"id":"TRZ7nAsYbEan"}}]}